{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Matrix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import spacy\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "#FILENAMES\n",
    "lexi = \"LexiconFinal.csv\"\n",
    "spacy_model = \"en_core_web_lg\"\n",
    "########################################################\n",
    "nlp = spacy.load(spacy_model)\n",
    "Lexicon = pandas.read_csv(lexi, usecols=[1, 2])\n",
    "\n",
    "#extract words\n",
    "words= Lexicon.iloc[:, 0]\n",
    "\n",
    "\n",
    "#Generate a list of vectors\n",
    "vectors = []\n",
    "for word in tqdm(words, desc = \"Loading vectors\"):\n",
    "  vectors.append(nlp(str(word)).vector)\n",
    "\n",
    "vectors = numpy.array(vectors)\n",
    "vectors = vectors.astype(numpy.float32)\n",
    "\n",
    "numpy.save(\"vectors.npy\", vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from openTSNE import TSNE\n",
    "from sklearn.preprocessing import normalize\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "new_lexi = \"Clusters_KMEANS.csv\"\n",
    "\n",
    "########################################################\n",
    "\n",
    "# Load vectors\n",
    "vectors = np.load(\"vectors.npy\")\n",
    "\n",
    "# Normalize vectors\n",
    "print(\"Normalizing\\n\")\n",
    "vectors = normalize(vectors)\n",
    "\n",
    "# Reduce dimensions with PCA\n",
    "print(\"Reducing dimensions with PCA\\n\")\n",
    "pca = faiss.PCAMatrix(300, 50)\n",
    "pca.train(vectors)\n",
    "vectors = pca.apply_py(vectors)\n",
    "\n",
    "\n",
    "\n",
    "# Generate cluster labels\n",
    "print(\"Using KMEANS\\n\")\n",
    "algo = KMeans(init='k-means++', n_clusters=300, random_state=42)\n",
    "clusters = algo.fit_predict(vectors)\n",
    "\n",
    "# Append cluster labels to lexicon and save\n",
    "print(\"\\nWriting to file\")\n",
    "Lexicon['Clusters'] = clusters\n",
    "Lexicon.to_csv(new_lexi, header=['Word', 'ID', 'Cluster'], index=False)\n",
    "\n",
    "\n",
    "# Reduce dimensionality for 3D visualization\n",
    "print(\"Reducing dimensionality to 3D for visualization\\n\")\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=40, perplexity=30, n_iter=1000)\n",
    "vectors_3d = tsne.fit(vectors)\n",
    "\n",
    "\n",
    "# Example data (replace with your own cluster-separated data)\n",
    "df = pd.DataFrame({\n",
    "    'x': vectors_3d[:, 0],\n",
    "    'y': vectors_3d[:, 1],\n",
    "    'z': vectors_3d[:, 2],\n",
    "    'Cluster': clusters\n",
    "})\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Iterate through clusters\n",
    "for cluster_id in df['Cluster'].unique():\n",
    "    cluster_points = df[df['Cluster'] == cluster_id][['x', 'y', 'z']].to_numpy()\n",
    "    \n",
    "    # Perform Delaunay triangulation in 3D\n",
    "    if len(cluster_points) >= 4:  # Minimum for triangulation\n",
    "        tri = Delaunay(cluster_points)\n",
    "        \n",
    "        # Add the mesh for the current cluster\n",
    "        fig.add_trace(go.Mesh3d(\n",
    "            x=cluster_points[:, 0],\n",
    "            y=cluster_points[:, 1],\n",
    "            z=cluster_points[:, 2],\n",
    "            i=tri.simplices[:, 0],  # Indices for the first vertex of each triangle\n",
    "            j=tri.simplices[:, 1],  # Indices for the second vertex\n",
    "            k=tri.simplices[:, 2],  # Indices for the third vertex\n",
    "            opacity=0.5,\n",
    "            color=f'rgb({np.random.randint(0, 255)}, {np.random.randint(0, 255)}, {np.random.randint(0, 255)})',  # Random color per cluster\n",
    "            name=f'Cluster {cluster_id}'\n",
    "        ))\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
